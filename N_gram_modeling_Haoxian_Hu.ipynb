{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haoxian Hu, hhu28@fordham.edu\n",
    "\n",
    "# estimated time: 20 min\n",
    "# start time: 23:15 04/26/2018\n",
    "# end time: 23:45 04/26/2018\n",
    "# time used: 30 min\n",
    "\n",
    "def nGrams():\n",
    "    path_file = input('Please enter the path of the json file including \".json\":\\n')\n",
    "    path_output = input('\\nPlease enter the output path of the Excel file:\\n')\n",
    "    print('\\nGenerating N-grams models..')\n",
    "    \n",
    "    import time\n",
    "    #record the start time\n",
    "    start = time.process_time()\n",
    "    \n",
    "    import pandas as pd\n",
    "    import nltk\n",
    "    from nltk import sent_tokenize, word_tokenize, pos_tag, FreqDist\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.util import ngrams\n",
    "    \n",
    "    #read headlines and short_descriptions\n",
    "    df = pd.read_json('{}'.format(path_file), lines=True)\n",
    "    headline = df['headline']                              \n",
    "    desc = df['short_description']\n",
    "    \n",
    "    #combine headline and short_descriptions\n",
    "    raw1 = headline.append(desc)\n",
    "    \n",
    "    #replace '\\u' with ' ' in the text\n",
    "    raw2 = list(raw1.replace('u',' '))\n",
    "    \n",
    "    #change list into string\n",
    "    str1 = \"\".join(raw2)\n",
    "    tokens = nltk.word_tokenize(str1)\n",
    "    \n",
    "    #change all tokens into lower case  \n",
    "    words1 = [w.lower() for w in tokens]                 \n",
    "    \n",
    "    #only keep text words, no numbers \n",
    "    words2 = [w for w in words1 if w.isalpha()]\n",
    "    \n",
    "    #remove stopwords such as \"and\", \"or\", making the result more meaningful\n",
    "    stopwords = stopwords.words('english')\n",
    "    words_nostopwords = [w for w in words2 if w not in stopwords]\n",
    "    \n",
    "    #reduce different tenses of the same word (e.g. 'ate', 'eaten' â†’ 'eat') \n",
    "    porter = nltk.PorterStemmer()                         \n",
    "    stem1 = [porter.stem(w) for w in words_nostopwords]\n",
    "    wnl = nltk.WordNetLemmatizer()                        \n",
    "    lemmatization = [wnl.lemmatize(w) for w in stem1]\n",
    "    \n",
    "    #Get the 1-gram frequency distribution in a decending order\n",
    "    freq_word = FreqDist(lemmatization)                  \n",
    "    sorted_freq_word = sorted(freq_word.items(),key = lambda k: k[1], reverse = True) \n",
    "    \n",
    "    #name the two columns as 'word','frequency'\n",
    "    sorted_freq_word = pd.DataFrame(sorted_freq_word)\n",
    "    sorted_freq_word.columns = ['word','frequency']\n",
    "    print('\\nThe word frequency model is ready.')\n",
    "    \n",
    "    #Get the bigram frequency distribution in a decending order\n",
    "    bigrams=list(ngrams(lemmatization,2))\n",
    "    freq_bigrams = FreqDist(bigrams)                     \n",
    "    sorted_freq_bigrams = sorted(freq_bigrams.items(),key = lambda k: k[1], reverse = True)\n",
    "    \n",
    "    #name the two columns as 'bigram','frequency'\n",
    "    sorted_freq_bigrams = pd.DataFrame(sorted_freq_bigrams)\n",
    "    sorted_freq_bigrams.columns = ['bigram','frequency']\n",
    "    print('\\nThe bigram model is ready.')\n",
    "    \n",
    "    print('\\nGenerating Excel file..')\n",
    "    #output two models into an Excel file\n",
    "\n",
    "    with pd.ExcelWriter('{}\\\\N_grams_results.xlsx'.format(path_output)) as writer: \n",
    "        sorted_freq_word.to_excel(writer, index=False, sheet_name='word_frequency')\n",
    "        sorted_freq_bigrams.to_excel(writer, index=False, sheet_name='bigrams')\n",
    "    \n",
    "    #record the end time\n",
    "    end = time.process_time()\n",
    "    \n",
    "    print(\"\\nN-grams models are ready.\\n\\nTime used in total:\",round(end-start, 0),'s')\n",
    "    \n",
    "nGrams()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
